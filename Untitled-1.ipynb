{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfastapi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mresponses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JSONResponse\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\n\u001b[32m     14\u001b[39m openai.api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mmy_open_ai_key\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msk‑demo\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m#blurred out the key so it won't exposed\u001b[39;00m\n\u001b[32m     16\u001b[39m app = FastAPI(title=\u001b[33m\"\u001b[39m\u001b[33mAI Log Summarizer\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[33m\"\u001b[39m\u001b[33m1.0.0\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI, UploadFile, File, Form\n",
    "from fastapi.responses import JSONResponse\n",
    "from pydantic import BaseModel\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"my_open_ai_key\", \"sk‑demo\") #blurred out the key so it won't exposed\n",
    "\n",
    "app = FastAPI(title=\"AI Log Summarizer\", version=\"1.0.0\")\n",
    "\n",
    "\n",
    "PRIORITY_MAP = {\"ERROR\": \"High\", \"WARNING\": \"Medium\", \"INFO\": \"Low\"}\n",
    "\n",
    "EMAIL_RE = r\"[\\w\\.-]+@[\\w\\.-]+\"\n",
    "IP_RE = r\"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\"\n",
    "\n",
    "INVALID_IP_RE = r\"\\b(?:\\d{1,3}\\.){1,2}\\d*\\b\"  # catches partial IPs\n",
    "EMAIL_PATTERN = re.compile(EMAIL_RE)\n",
    "IP_PATTERN = re.compile(IP_RE)\n",
    "\n",
    "\n",
    "def parse_log_line(line: str):\n",
    "    \"\"\"Return timestamp, level, raw message.\"\"\"\n",
    "    m = re.match(r\"\\[(.*?)\\]\\s+(\\w+):\\s+(.*)\", line)\n",
    "    if m:\n",
    "        return m.group(1), m.group(2), m.group(3)\n",
    "    return None, None, line.strip()\n",
    "\n",
    "\n",
    "def is_invalid_ip(ip: str) -> bool:\n",
    "    return not re.fullmatch(IP_RE, ip)\n",
    "\n",
    "\n",
    "def is_invalid_email(email: str) -> bool:\n",
    "    if not re.fullmatch(EMAIL_RE, email):\n",
    "        return True\n",
    "    if \"..\" in email or email.count('@') != 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def mask_tokens(message: str, email_map: Dict[str, str], ip_map: Dict[str, str]):\n",
    "    \"\"\"Replace sensitive IDs with neutral tokens & build mapping.\"\"\"\n",
    "\n",
    "    def _replace(match, _map, prefix):\n",
    "        item = match.group(0)\n",
    "        if item not in _map:\n",
    "            _map[item] = f\"{prefix}{len(_map) + 1:02d}\"\n",
    "        return _map[item]\n",
    "\n",
    "    msg = re.sub(EMAIL_RE, lambda m: _replace(m, email_map, \"USERNAME-\"), message)\n",
    "    msg = re.sub(IP_RE, lambda m: _replace(m, ip_map, \"IP-ADDRESS-\"), msg)\n",
    "    return msg\n",
    "\n",
    "\n",
    "class LogSummaryRequest(BaseModel):\n",
    "    session_id: Optional[str] = None  # reused for refinement\n",
    "    priority: Optional[str] = \"Low\"   # user‑set if desired\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    session_id: str\n",
    "    rating: int  # 1‑5 star\n",
    "    comment: Optional[str] = None\n",
    "\n",
    "\n",
    "SESSIONS: Dict[str, Dict] = {}\n",
    "\n",
    "\n",
    "@app.post(\"/upload\")\n",
    "async def upload_log(file: UploadFile = File(...)):\n",
    "    \"\"\"Parse & store uploaded log; return session_id.\"\"\"\n",
    "    raw = (await file.read()).decode(\"utf‑8\", errors=\"ignore\").splitlines()\n",
    "    email_map, ip_map, rows = {}, {}, []\n",
    "\n",
    "    for line in raw:\n",
    "        ts, lvl, msg = parse_log_line(line)\n",
    "        if ts is None:\n",
    "            continue\n",
    "        masked = mask_tokens(msg, email_map, ip_map)\n",
    "        priority = PRIORITY_MAP.get(lvl, \"Low\")\n",
    "        invalid = any(is_invalid_ip(ip) for ip in re.findall(IP_RE, msg)) or \\\n",
    "                  any(is_invalid_email(em) for em in re.findall(EMAIL_RE, msg))\n",
    "        rows.append((ts, lvl, masked, priority, invalid))\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"timestamp\", \"level\", \"masked_message\", \"priority\", \"invalid\"])\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "    session_id = str(uuid.uuid4())\n",
    "    SESSIONS[session_id] = {\n",
    "        \"df\": df,\n",
    "        \"email_map\": email_map,\n",
    "        \"ip_map\": ip_map,\n",
    "        \"history\": [],  # GPT conversation history\n",
    "        \"feedback\": []\n",
    "    }\n",
    "    return {\"session_id\": session_id, \"message\": \"Log uploaded and parsed.\"}\n",
    "\n",
    "\n",
    "@app.post(\"/summarize/{session_id}\")\n",
    "async def summarize(session_id: str, body: LogSummaryRequest):\n",
    "    \"\"\"Generate or refine summary using GPT with session context.\"\"\"\n",
    "    if session_id not in SESSIONS:\n",
    "        return JSONResponse({\"error\": \"Invalid session\"}, status_code=404)\n",
    "\n",
    "    df = SESSIONS[session_id][\"df\"]\n",
    "    # Basic aggregation (could be expanded)\n",
    "    grouped = df.groupby([\"level\", \"masked_message\", \"priority\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "    prompt = (\n",
    "        \"You are LogGPT. Summarize the following log clusters with potential root causes.\"\n",
    "        \"\\nFormat: LEVEL | PRIORITY | MSG | COUNT.\\n\"\n",
    "    )\n",
    "    for _, row in grouped.iterrows():\n",
    "        prompt += f\"{row['level']} | {row['priority']} | {row['masked_message']} | {row['count']}\\n\"\n",
    "\n",
    "    # Include previous iterations for refinement\n",
    "    history = SESSIONS[session_id][\"history\"]\n",
    "    if history:\n",
    "        prompt = history[-1] + \"\\nUSER_FEEDBACK: Please refine based on above.\\n\" + prompt\n",
    "\n",
    "    # Call OpenAI\n",
    "    try:\n",
    "        rsp = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=400\n",
    "        )\n",
    "        summary = rsp.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        summary = f\"[OpenAI Error] {e}\"\n",
    "\n",
    "    history.append(prompt)\n",
    "    SESSIONS[session_id][\"history\"] = history\n",
    "    return {\"summary\": summary, \"clusters\": len(grouped), \"priority_count\": grouped.priority.value_counts().to_dict()}\n",
    "\n",
    "\n",
    "@app.post(\"/feedback\")\n",
    "async def feedback(body: Feedback):\n",
    "    \"\"\"Store user rating; simple weight adj placeholder.\"\"\"\n",
    "    sess = SESSIONS.get(body.session_id)\n",
    "    if not sess:\n",
    "        return JSONResponse({\"error\": \"Invalid session id\"}, status_code=404)\n",
    "    sess[\"feedback\"].append({\"rating\": body.rating, \"comment\": body.comment})\n",
    "    return {\"status\": \"Feedback recorded\"}\n",
    "\n",
    "\n",
    "@app.get(\"/session/{session_id}\")\n",
    "async def session_info(session_id: str):\n",
    "    if session_id not in SESSIONS:\n",
    "        return JSONResponse({\"error\": \"Invalid session\"}, status_code=404)\n",
    "    s = SESSIONS[session_id]\n",
    "    return {\n",
    "        \"rows\": len(s[\"df\"]),\n",
    "        \"history_entries\": len(s[\"history\"]),\n",
    "        \"feedback_count\": len(s[\"feedback\"])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
